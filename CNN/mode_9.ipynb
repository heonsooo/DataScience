{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 증식해서 넣어봅시다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 images belonging to 3 classes.\n",
      "Found 9000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './images2/train',\n",
    "        target_size = (300,300),\n",
    "        batch_size=50,\n",
    "#         color_mode ='rgb',\n",
    "        classes = ['food','interior', 'exterior'],\n",
    "        shuffle =True,\n",
    "        seed = 42,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        './images2/test',\n",
    "#         classes =[],\n",
    "        target_size=(300,300),\n",
    "        batch_size=10,\n",
    "#         color_mode ='rgb',\n",
    "        shuffle =True,\n",
    "        seed = 42,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "iterations = 50\n",
    "\n",
    "train_plus = train_datagen.flow_from_directory(\n",
    "    './images2/train',\n",
    "    target_size = (300,300),\n",
    "    batch_size = 10,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "for i in enumerate(range(iterations)):\n",
    "    img, label = train_plus.next()\n",
    "#     n_img = len(label)\n",
    "    \n",
    "#     base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "#     for idx in range(n_img - 1):\n",
    "#         img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "#         base = np.hstack((base, img2))\n",
    "#     images.append(base)\n",
    " \n",
    "# img = images[0]\n",
    "# for idx in range(len(images) - 1):\n",
    "#     img = np.vstack((img, images[idx + 1]))\n",
    "# cv2.imshow('result', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 298, 298, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 147, 147, 2)       578       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 73, 73, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10658)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 31977     \n",
      "=================================================================\n",
      "Total params: 33,451\n",
      "Trainable params: 33,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.0179 - accuracy: 0.4780 - val_loss: 1.0658 - val_accuracy: 0.3900\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.0054 - accuracy: 0.4840 - val_loss: 0.9752 - val_accuracy: 0.4900\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.9042 - accuracy: 0.5640 - val_loss: 0.8837 - val_accuracy: 0.5600\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.9170 - accuracy: 0.5460 - val_loss: 0.8855 - val_accuracy: 0.5300\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.8109 - accuracy: 0.6040 - val_loss: 0.9420 - val_accuracy: 0.5100\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.8715 - accuracy: 0.5980 - val_loss: 0.8605 - val_accuracy: 0.5800\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.8346 - accuracy: 0.5940 - val_loss: 0.7626 - val_accuracy: 0.6200\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.7589 - accuracy: 0.6580 - val_loss: 0.9192 - val_accuracy: 0.5800\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.8411 - accuracy: 0.6440 - val_loss: 0.7656 - val_accuracy: 0.6200\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.8826 - accuracy: 0.5900 - val_loss: 0.7605 - val_accuracy: 0.6200\n",
      "INFO:tensorflow:Assets written to: model-8\\assets\n",
      "-- Evaluate --\n",
      "accuracy: 68.00%\n",
      "-- Predict --\n",
      "{'0_food': 0, '1_interior': 1, '2_exterior': 2}\n",
      "[[0.764 0.218 0.018]\n",
      " [0.671 0.227 0.102]\n",
      " [0.289 0.569 0.142]\n",
      " [0.302 0.273 0.426]\n",
      " [0.652 0.332 0.016]\n",
      " [0.487 0.440 0.073]\n",
      " [0.729 0.261 0.010]\n",
      " [0.348 0.416 0.236]\n",
      " [0.899 0.097 0.004]\n",
      " [0.403 0.365 0.231]\n",
      " [0.486 0.373 0.141]\n",
      " [0.562 0.392 0.046]\n",
      " [0.872 0.116 0.011]\n",
      " [0.266 0.280 0.453]\n",
      " [0.931 0.066 0.003]\n",
      " [0.321 0.413 0.266]\n",
      " [0.515 0.219 0.266]\n",
      " [0.375 0.441 0.184]\n",
      " [0.661 0.322 0.017]\n",
      " [0.345 0.512 0.143]\n",
      " [0.690 0.252 0.058]\n",
      " [0.720 0.231 0.048]\n",
      " [0.278 0.422 0.300]\n",
      " [0.117 0.328 0.555]\n",
      " [0.101 0.299 0.600]\n",
      " [0.650 0.313 0.037]\n",
      " [0.997 0.002 0.000]\n",
      " [0.454 0.370 0.176]\n",
      " [0.326 0.381 0.293]\n",
      " [0.584 0.373 0.043]\n",
      " [0.151 0.619 0.231]\n",
      " [0.571 0.321 0.108]\n",
      " [0.378 0.609 0.014]\n",
      " [0.219 0.327 0.453]\n",
      " [0.672 0.201 0.127]\n",
      " [0.580 0.402 0.018]\n",
      " [0.780 0.146 0.074]\n",
      " [0.637 0.340 0.022]\n",
      " [0.147 0.394 0.459]\n",
      " [0.139 0.403 0.458]\n",
      " [0.728 0.266 0.006]\n",
      " [0.258 0.591 0.151]\n",
      " [0.269 0.404 0.327]\n",
      " [0.182 0.400 0.419]\n",
      " [0.204 0.331 0.465]\n",
      " [0.349 0.510 0.140]\n",
      " [0.727 0.261 0.012]\n",
      " [0.626 0.226 0.148]\n",
      " [0.358 0.452 0.190]\n",
      " [0.922 0.060 0.018]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 input_shape=(300,300,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(16, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(32, activation='selu'))\n",
    "# model.add(Dense(2, activation='selu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정 및 요약\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=10,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=10)\n",
    "\n",
    "model.save('model-8')\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=10)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
