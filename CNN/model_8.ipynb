{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 images belonging to 3 classes.\n",
      "Found 9000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './images2/train',\n",
    "        target_size = (300,300),\n",
    "        batch_size=50,\n",
    "#         color_mode ='rgb',\n",
    "        classes = ['food','interior', 'exterior'],\n",
    "        shuffle =True,\n",
    "        seed = 42,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        './images2/test',\n",
    "        classes =[],\n",
    "        target_size=(300,300),\n",
    "        batch_size=10,\n",
    "#         color_mode ='rgb',\n",
    "        shuffle =True,\n",
    "        seed = 42,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 2)       56        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 2)       38        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10658)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 31977     \n",
      "=================================================================\n",
      "Total params: 32,071\n",
      "Trainable params: 32,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-4-e858789a7747>:23: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0825 - accuracy: 0.4180 - val_loss: 1.0414 - val_accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 9s 897ms/step - loss: 1.0460 - accuracy: 0.4600 - val_loss: 1.0047 - val_accuracy: 0.5900\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 8s 846ms/step - loss: 1.0143 - accuracy: 0.4860 - val_loss: 0.9559 - val_accuracy: 0.5200\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 8s 849ms/step - loss: 1.0767 - accuracy: 0.4380 - val_loss: 1.0624 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 9s 896ms/step - loss: 1.0031 - accuracy: 0.4880 - val_loss: 1.0814 - val_accuracy: 0.3700\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 10s 973ms/step - loss: 1.0326 - accuracy: 0.4760 - val_loss: 0.9853 - val_accuracy: 0.6200\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 9s 943ms/step - loss: 0.9870 - accuracy: 0.5340 - val_loss: 1.0211 - val_accuracy: 0.4600\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 9s 891ms/step - loss: 0.9447 - accuracy: 0.5720 - val_loss: 0.9789 - val_accuracy: 0.4900\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 9s 871ms/step - loss: 0.9403 - accuracy: 0.5560 - val_loss: 0.8670 - val_accuracy: 0.6700\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 9s 855ms/step - loss: 0.8881 - accuracy: 0.6040 - val_loss: 0.8658 - val_accuracy: 0.6000\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model-8\\assets\n",
      "-- Evaluate --\n",
      "WARNING:tensorflow:From <ipython-input-4-e858789a7747>:29: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "accuracy: 57.00%\n",
      "-- Predict --\n",
      "WARNING:tensorflow:From <ipython-input-4-e858789a7747>:34: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "{'0_food': 0, '1_interior': 1, '2_exterior': 2}\n",
      "[[0.721 0.174 0.104]\n",
      " [0.678 0.223 0.099]\n",
      " [0.644 0.170 0.186]\n",
      " [0.500 0.365 0.135]\n",
      " [0.792 0.127 0.081]\n",
      " [0.204 0.318 0.478]\n",
      " [0.400 0.474 0.125]\n",
      " [0.459 0.347 0.194]\n",
      " [0.573 0.231 0.196]\n",
      " [0.385 0.378 0.237]\n",
      " [0.129 0.516 0.356]\n",
      " [0.197 0.520 0.283]\n",
      " [0.223 0.553 0.225]\n",
      " [0.737 0.220 0.042]\n",
      " [0.262 0.367 0.371]\n",
      " [0.293 0.338 0.369]\n",
      " [0.455 0.210 0.335]\n",
      " [0.332 0.339 0.328]\n",
      " [0.413 0.237 0.350]\n",
      " [0.557 0.236 0.208]\n",
      " [0.162 0.382 0.456]\n",
      " [0.686 0.166 0.148]\n",
      " [0.668 0.158 0.174]\n",
      " [0.363 0.324 0.313]\n",
      " [0.549 0.263 0.187]\n",
      " [0.453 0.402 0.145]\n",
      " [0.895 0.077 0.028]\n",
      " [0.445 0.236 0.319]\n",
      " [0.413 0.449 0.138]\n",
      " [0.074 0.361 0.565]\n",
      " [0.591 0.255 0.155]\n",
      " [0.365 0.355 0.280]\n",
      " [0.277 0.480 0.243]\n",
      " [0.488 0.375 0.137]\n",
      " [0.108 0.284 0.609]\n",
      " [0.700 0.160 0.140]\n",
      " [0.546 0.161 0.293]\n",
      " [0.726 0.123 0.151]\n",
      " [0.562 0.280 0.158]\n",
      " [0.588 0.244 0.169]\n",
      " [0.176 0.643 0.181]\n",
      " [0.779 0.170 0.051]\n",
      " [0.227 0.479 0.294]\n",
      " [0.381 0.254 0.365]\n",
      " [0.561 0.250 0.190]\n",
      " [0.345 0.293 0.362]\n",
      " [0.250 0.537 0.213]\n",
      " [0.590 0.261 0.148]\n",
      " [0.661 0.163 0.176]\n",
      " [0.286 0.570 0.144]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(2, kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 input_shape=(300,300,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(2, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(32, activation='selu'))\n",
    "# model.add(Dense(2, activation='selu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정 및 요약\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=10,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=10)\n",
    "\n",
    "model.save('model-8')\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=10)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_sample(model,X_test, y_test, test_id= -1 ):\n",
    "    if test_id <0 :\n",
    "        from random import randrange\n",
    "        test_sample_id = randrange(10000)\n",
    "    else:\n",
    "        test_sample_id = test_id\n",
    "    \n",
    "    test_image =X_test[test_sample_id]\n",
    "#     plt.imshow(test_images[123])\n",
    "\n",
    "    \n",
    "    test_image = test_image.reshape(1,300,300,3)\n",
    "    \n",
    "    y_actual = y_test[test_sample_id].tolist().index(1)\n",
    "    print('y_actual number = ', y_actual)\n",
    "    \n",
    "    y_pred = model.predict(test_image)\n",
    "    print(\"y_pred = \", y_pred)\n",
    "    \n",
    "    y_pred_num = np.argmax(y_pred, axis = 1)[0]\n",
    "    print('y_pred number = ', y_pred_num)\n",
    "    return y_actual , y_pred_num\n",
    "\n",
    "def test_load_data():\n",
    "    train_images = []       \n",
    "    train_labels = []\n",
    "    shape = (300,300)  \n",
    "    train_path = './image_test'\n",
    "\n",
    "    for classes in ['f','i','e']:\n",
    "        for filename in os.listdir('./image_test'):\n",
    "            if classes == filename[0]:\n",
    "                img = cv2.imread(os.path.join(train_path,filename))\n",
    "                train_labels.append(filename[2:0:-1])\n",
    "\n",
    "                # Resize all images to a specific shape\n",
    "                #img = cv2.resize(img,shape)\n",
    "\n",
    "                train_images.append(img)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # Converting labels into One Hot encoded sparse matrix\n",
    "\n",
    "    # 음식, 실내 ,실외 순으로 들어가기 위해 index 처리\n",
    "    # train_labels = sorted(train_labels)\n",
    "    # print(train_labels)\n",
    "\n",
    "    train_labels = pd.get_dummies((train_labels)).values\n",
    "    # print(train_labels)\n",
    "    # Converting train_images to array\n",
    "    train_images = np.array(train_images)\n",
    "\n",
    "    # Splitting Training data into train and validation dataset\n",
    "\n",
    "    train_images ,train_labels= shuffle(train_images ,train_labels, random_state = 42) \n",
    "\n",
    "    return train_images, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__' :\n",
    "    n = 0\n",
    "    \n",
    "    X_test , y_test = test_load_data()\n",
    "    model = load_model('model-8')\n",
    "    for i in range(20):\n",
    "        y_actual , y_pred_num = predict_image_sample(model,X_test, y_test,test_id = i)\n",
    "        if y_actual == y_pred_num:\n",
    "            n += 1 \n",
    "        else : pass\n",
    "print('전체 횟수 :', i,' '*10,'예측 성공 횟수',n,'\\n'*2 ,'정확도 = ', (n/i)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
