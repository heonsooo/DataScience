{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 증식해서 넣어봅시다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 images belonging to 3 classes.\n",
      "Found 9000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './images2/train',\n",
    "        target_size = (300,300),\n",
    "        batch_size=50,\n",
    "#         color_mode ='rgb',\n",
    "        classes = ['food','interior', 'exterior'],\n",
    "        shuffle =True,\n",
    "        seed = 42,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        './images2/test',\n",
    "#         classes =[],\n",
    "        target_size=(300,300),\n",
    "        batch_size=10,\n",
    "#         color_mode ='rgb',\n",
    "        shuffle =True,\n",
    "        seed = 42,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "iterations = 150\n",
    "\n",
    "train_plus = train_datagen.flow_from_directory(\n",
    "    './images2/train',\n",
    "    target_size = (300,300),\n",
    "    batch_size = 10,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "for i in enumerate(range(iterations)):\n",
    "    img, label = train_plus.next()\n",
    "#     n_img = len(label)\n",
    "    \n",
    "#     base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "#     for idx in range(n_img - 1):\n",
    "#         img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "#         base = np.hstack((base, img2))\n",
    "#     images.append(base)\n",
    " \n",
    "# img = images[0]\n",
    "# for idx in range(len(images) - 1):\n",
    "#     img = np.vstack((img, images[idx + 1]))\n",
    "# cv2.imshow('result', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 298, 298, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 147, 147, 32)      18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 170528)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 511587    \n",
      "=================================================================\n",
      "Total params: 531,843\n",
      "Trainable params: 531,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 15s 3s/step - loss: 11.4837 - accuracy: 0.4000 - val_loss: 4.1613 - val_accuracy: 0.4800\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.3323 - accuracy: 0.4640 - val_loss: 4.2648 - val_accuracy: 0.4400\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.8686 - accuracy: 0.3880 - val_loss: 1.8215 - val_accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.7560 - accuracy: 0.4640 - val_loss: 2.2668 - val_accuracy: 0.4200\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.9560 - accuracy: 0.4520 - val_loss: 1.9381 - val_accuracy: 0.5600\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.5142 - accuracy: 0.5400 - val_loss: 1.8872 - val_accuracy: 0.5200\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0733 - accuracy: 0.5880 - val_loss: 1.1551 - val_accuracy: 0.5400\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9311 - accuracy: 0.5960 - val_loss: 1.1143 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.8730 - accuracy: 0.6080 - val_loss: 0.8365 - val_accuracy: 0.6800\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9718 - accuracy: 0.5640 - val_loss: 0.8875 - val_accuracy: 0.5800\n",
      "INFO:tensorflow:Assets written to: model-11\\assets\n",
      "-- Evaluate --\n",
      "accuracy: 70.00%\n",
      "-- Predict --\n",
      "{'0_food': 0, '1_interior': 1, '2_exterior': 2}\n",
      "[[0.027 0.154 0.819]\n",
      " [0.380 0.513 0.107]\n",
      " [0.541 0.310 0.149]\n",
      " [0.394 0.563 0.043]\n",
      " [0.696 0.237 0.066]\n",
      " [0.646 0.262 0.092]\n",
      " [0.613 0.261 0.126]\n",
      " [0.943 0.049 0.008]\n",
      " [0.358 0.306 0.335]\n",
      " [0.285 0.600 0.114]\n",
      " [0.226 0.206 0.568]\n",
      " [0.876 0.097 0.027]\n",
      " [0.924 0.072 0.004]\n",
      " [0.187 0.645 0.168]\n",
      " [0.946 0.035 0.019]\n",
      " [0.447 0.491 0.062]\n",
      " [0.600 0.339 0.061]\n",
      " [0.435 0.285 0.281]\n",
      " [0.221 0.570 0.209]\n",
      " [0.157 0.495 0.349]\n",
      " [0.126 0.831 0.043]\n",
      " [0.012 0.099 0.889]\n",
      " [0.523 0.265 0.212]\n",
      " [0.457 0.215 0.328]\n",
      " [0.282 0.511 0.207]\n",
      " [0.634 0.284 0.083]\n",
      " [0.357 0.514 0.130]\n",
      " [0.410 0.196 0.394]\n",
      " [0.685 0.246 0.069]\n",
      " [0.026 0.064 0.911]\n",
      " [0.082 0.604 0.314]\n",
      " [0.728 0.149 0.124]\n",
      " [0.483 0.382 0.135]\n",
      " [0.754 0.205 0.040]\n",
      " [0.232 0.299 0.469]\n",
      " [0.126 0.663 0.211]\n",
      " [0.029 0.107 0.864]\n",
      " [0.646 0.125 0.229]\n",
      " [0.002 0.022 0.976]\n",
      " [0.670 0.301 0.029]\n",
      " [0.013 0.139 0.848]\n",
      " [0.085 0.811 0.105]\n",
      " [0.275 0.458 0.267]\n",
      " [0.207 0.501 0.293]\n",
      " [0.316 0.417 0.266]\n",
      " [0.184 0.520 0.296]\n",
      " [0.243 0.421 0.336]\n",
      " [0.727 0.267 0.005]\n",
      " [0.940 0.056 0.004]\n",
      " [0.997 0.003 0.000]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3),\n",
    "                 activation='selu',\n",
    "                 input_shape=(300,300,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation='selu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(32, activation='selu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정 및 요약\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=5,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)\n",
    "\n",
    "model.save('model-11')\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_load_data():\n",
    "    train_images = []       \n",
    "    train_labels = []\n",
    "    shape = (300,300)  \n",
    "    train_path = './image_test'\n",
    "\n",
    "    for classes in ['f','i','e']:\n",
    "        for filename in os.listdir('./image_test'):\n",
    "            if classes == filename[0]:\n",
    "                img = cv2.imread(os.path.join(train_path,filename))\n",
    "                train_labels.append(filename[2:0:-1])\n",
    "\n",
    "                # Resize all images to a specific shape\n",
    "                #img = cv2.resize(img,shape)\n",
    "\n",
    "                train_images.append(img)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # Converting labels into One Hot encoded sparse matrix\n",
    "\n",
    "    # 음식, 실내 ,실외 순으로 들어가기 위해 index 처리\n",
    "    # train_labels = sorted(train_labels)\n",
    "    # print(train_labels)\n",
    "\n",
    "    train_labels = pd.get_dummies((train_labels)).values\n",
    "    # print(train_labels)\n",
    "    # Converting train_images to array\n",
    "    train_images = np.array(train_images)\n",
    "\n",
    "    # Splitting Training data into train and validation dataset\n",
    "\n",
    "    train_images ,train_labels= shuffle(train_images ,train_labels, random_state = 42) \n",
    "\n",
    "    return train_images, train_labels\n",
    "\n",
    "def predict_image_sample(model,X_test, y_test, test_id= -1 ):\n",
    "    if test_id <0 :\n",
    "        from random import randrange\n",
    "        test_sample_id = randrange(10000)\n",
    "    else:\n",
    "        test_sample_id = test_id\n",
    "    \n",
    "    test_image =X_test[test_sample_id]\n",
    "#     plt.imshow(test_images[123])\n",
    "\n",
    "    \n",
    "    test_image = test_image.reshape(1,300,300,3)\n",
    "    \n",
    "    y_actual = y_test[test_sample_id].tolist().index(1)\n",
    "    print('y_actual number = ', y_actual)\n",
    "    \n",
    "    y_pred = model.predict(test_image)\n",
    "    print(\"y_pred = \", y_pred)\n",
    "    \n",
    "    y_pred_num = np.argmax(y_pred, axis = 1)[0]\n",
    "    print('y_pred number = ', y_pred_num)\n",
    "    return y_actual , y_pred_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  1\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "y_actual number =  0\n",
      "y_pred =  [[0.000 0.000 1.000]]\n",
      "y_pred number =  2\n",
      "전체 횟수 : 19            예측 성공 횟수 0 \n",
      "\n",
      " 정확도 =  0.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    n = 0\n",
    "    model = load_model('model-10')\n",
    "    X_test, y_test =test_load_data()\n",
    "    for i in range(20):\n",
    "        y_actual , y_pred_num = predict_image_sample(model,X_test, y_test,test_id = i)\n",
    "        \n",
    "        if y_actual == y_pred_num:\n",
    "            n += 1 \n",
    "        else : pass\n",
    "print('전체 횟수 :', i,' '*10,'예측 성공 횟수',n,'\\n'*2 ,'정확도 = ', (n/i)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
