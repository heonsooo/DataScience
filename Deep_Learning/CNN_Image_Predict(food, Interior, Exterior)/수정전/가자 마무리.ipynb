{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#에러 코드 핸들링\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    " \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "#디렉토리 -> numpy 변환\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# 이미지 -> 디렉토리 및 라벨링\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    " \n",
    "\n",
    "#모델링\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import  Input, Conv2D, MaxPooling2D, Dense, Flatten, experimental, Dropout\n",
    "\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import datetime\n",
    " \n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 images belonging to 3 classes.\n",
      "Found 7200 images belonging to 3 classes.\n",
      "Found 9000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증폭\n",
    "\n",
    "train_data_augmentation = ImageDataGenerator(\n",
    "\n",
    "    validation_split = 0.2,\n",
    "\n",
    "    rotation_range=10,\n",
    "\n",
    "    zoom_range = 0.3,\n",
    "\n",
    "    width_shift_range=0.2,\n",
    "\n",
    "    height_shift_range=0.2)\n",
    "\n",
    "#train 데이터 설정 \n",
    "\n",
    "train_data = train_data_augmentation.flow_from_directory(\n",
    "\n",
    "        './images2/train',\n",
    "\n",
    "        target_size = (300,300),\n",
    "\n",
    "        batch_size=150,\n",
    "\n",
    "        #color_mode ='rgb',\n",
    "\n",
    "        classes = ['food','interior', 'exterior'],\n",
    "\n",
    "        shuffle =True,\n",
    "\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "# validation 데이터 설정\n",
    "\n",
    "validation_data = train_data_augmentation.flow_from_directory(\n",
    "\n",
    "        './images2/train',\n",
    "\n",
    "        target_size = (300,300),\n",
    "\n",
    "        batch_size=100,\n",
    "\n",
    "        classes = ['food','interior', 'exterior'],\n",
    "\n",
    "        shuffle =True,\n",
    "\n",
    "        class_mode='categorical',\n",
    "\n",
    "        subset='validation')\n",
    "\n",
    " \n",
    "#test 데이터 설정\n",
    "\n",
    "test_data = ImageDataGenerator().flow_from_directory(\n",
    "\n",
    "        './images2/test',\n",
    "\n",
    "        classes = ['food','interior', 'exterior'],\n",
    "\n",
    "        target_size=(300,300),\n",
    "\n",
    "        batch_size=25,\n",
    "\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_Go_X7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "Conv_layer1 (Conv2D)         (None, 298, 298, 32)      896       \n",
      "_________________________________________________________________\n",
      "Pooling_layer2 (MaxPooling2D (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "Conv_layer3 (Conv2D)         (None, 147, 147, 96)      27744     \n",
      "_________________________________________________________________\n",
      "Pooling_layer4 (MaxPooling2D (None, 73, 73, 96)        0         \n",
      "_________________________________________________________________\n",
      "Conv_layer5 (Conv2D)         (None, 71, 71, 64)        55360     \n",
      "_________________________________________________________________\n",
      "Pooling_layer6 (MaxPooling2D (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv_layer7 (Conv2D)         (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "Pooling_layer8 (MaxPooling2D (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "FC_layer9 (Dense)            (None, 160)               5243040   \n",
      "_________________________________________________________________\n",
      "FC_layer10 (Dense)           (None, 20)                3220      \n",
      "_________________________________________________________________\n",
      "output_layer11 (Dense)       (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 5,404,179\n",
      "Trainable params: 5,404,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fitting start 2020-12-17 18:14:47.875400\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "\n",
    "Input(shape=(300,300,3), name='input_layer'),\n",
    "\n",
    "experimental.preprocessing.Rescaling(1./255),\n",
    "\n",
    "Conv2D(32,(3,3), activation='relu',name='Conv_layer1'),\n",
    "\n",
    "MaxPooling2D(pool_size=(2,2),name='Pooling_layer2'),\n",
    "    \n",
    "\n",
    "Conv2D(96,(3,3), activation='relu',name='Conv_layer3'),\n",
    "\n",
    "MaxPooling2D(pool_size=(2,2),name='Pooling_layer4'),\n",
    "\n",
    " \n",
    "\n",
    "Conv2D(64,(3,3), activation='relu',name='Conv_layer5'),\n",
    "\n",
    "MaxPooling2D(pool_size=(2,2),name='Pooling_layer6'),\n",
    "    \n",
    "\n",
    "Dropout(0.5),\n",
    "\n",
    "Conv2D(128,(3,3), activation='relu',name='Conv_layer7'),\n",
    "\n",
    "MaxPooling2D(pool_size=(2,2),name='Pooling_layer8'),\n",
    "\n",
    "Flatten(),\n",
    "\n",
    "Dense(160, activation='relu',name='FC_layer9', kernel_initializer='glorot_uniform',),\n",
    "\n",
    "Dense(20, activation='relu',name='FC_layer10', kernel_initializer='glorot_uniform',),\n",
    "\n",
    "Dense(3, activation='softmax', name='output_layer11')\n",
    "\n",
    "])\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "# 3. 모델 학습과정 설정 및 요약\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = datetime.datetime.now()\n",
    "print('fitting start', a)\n",
    "\n",
    "# 4. 모델 학습\n",
    "def model_():\n",
    "    history = model.fit(\n",
    "\n",
    "        train_data,\n",
    "\n",
    "        steps_per_epoch=15,\n",
    "\n",
    "        epochs=30,\n",
    "\n",
    "        validation_data=validation_data,\n",
    "\n",
    "        validation_steps=10)\n",
    "\n",
    "    model.save('Model_Go_X7')\n",
    "    return history\n",
    "\n",
    "\n",
    "model.save('Model_Go_X7')\n",
    "b = datetime.datetime.now()\n",
    "history = model_()\n",
    "print('Fitting End', b)\n",
    "print('Fitting Time =' , b-a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model_Go_XX7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model_()\n",
    "def plot_loss_curve(history):\n",
    "\n",
    "    plt.figure(figsize = (5,3))\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "\n",
    "    plt.plot(history['val_loss'])\n",
    "\n",
    "\n",
    "    plt.title('model loss')\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    plt.legend(['train','test'], loc = 'upper right')\n",
    "\n",
    "    plt.show\n",
    "\n",
    "    \n",
    "def plot_accuracy_curve(history):\n",
    "\n",
    "    plt.figure(figsize = (5,3))\n",
    "\n",
    "    plt.plot(history['accuracy'])\n",
    "\n",
    "    plt.plot(history['val_accuracy'])\n",
    "\n",
    "\n",
    "    plt.title('model accuracy')\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "    plt.ylabel('accuracy')\n",
    "\n",
    "    plt.legend(['train','test'], loc = 'upper right')\n",
    "\n",
    "    plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_curve(history.history)\n",
    "\n",
    "print('train accuracy ={} , validation accuracy ={}' .format(\n",
    "                                                            round(history.history['accuracy'][-1],5), \n",
    "                                                            round(history.history['val_accuracy'][-1],5) ))\n",
    "plot_loss_curve(history.history)\n",
    "print('train loss ={} ,     validation loss ={}' .format(\n",
    "                                                        round(history.history['loss'][-1],5), \n",
    "                                                        round(history.history['val_loss'][-1],5) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
