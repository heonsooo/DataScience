{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 증식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential,load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 36000 images belonging to 3 classes.\n",
      "Found 9000 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "path_trian ='C:/Users/82103/1_여기서 실행/데이터사이언스개론_최종과제/images2/train'\n",
    "path_test = 'C:/Users/82103/1_여기서 실행/데이터사이언스개론_최종과제/images2/test'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        path_trian,\n",
    "        target_size = (300,300),\n",
    "        batch_size=50,\n",
    "        classes = ['food','interior', 'exterior'],\n",
    "        shuffle =True,\n",
    "        seed = 42,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        path_test,\n",
    "        classes = ['food','interior', 'exterior'],\n",
    "        target_size=(300,300),\n",
    "        batch_size=10,\n",
    "        shuffle =True,\n",
    "        seed = 42,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 36000 images belonging to 3 classes.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nfor i in enumerate(range(iterations)):\\n    img, label = train_plus.next()\\n     n_img = len(label)\\n    \\n     base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\\n     for idx in range(n_img - 1):\\n         img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\\n         base = np.hstack((base, img2))\\n         images.append(base)\\n \\nimg = images[0]\\nfor idx in range(len(images) - 1):\\n    img = np.vstack((img, images[idx + 1]))\\n    cv2.imshow('result', img)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "iterations = 100\n",
    "\n",
    "train_plus = train_datagen.flow_from_directory(\n",
    "    path_trian,\n",
    "    target_size = (300,300),\n",
    "    batch_size = 10,\n",
    "    class_mode = 'categorical')\n",
    "'''\n",
    "for i in enumerate(range(iterations)):\n",
    "    img, label = train_plus.next()\n",
    "     n_img = len(label)\n",
    "    \n",
    "     base = cv2.cvtColor(img[0], cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "     for idx in range(n_img - 1):\n",
    "         img2 = cv2.cvtColor(img[idx + 1], cv2.COLOR_RGB2BGR)\n",
    "         base = np.hstack((base, img2))\n",
    "         images.append(base)\n",
    " \n",
    "img = images[0]\n",
    "for idx in range(len(images) - 1):\n",
    "    img = np.vstack((img, images[idx + 1]))\n",
    "    cv2.imshow('result', img)\n",
    "'''"
   ]
  },
  {
   "source": [
    "Modeling 및 성능평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 298, 298, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 147, 147, 16)      4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 73, 73, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 85264)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 255795    \n",
      "=================================================================\n",
      "Total params: 261,315\n",
      "Trainable params: 261,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 1.1751 - accuracy: 0.4025 - val_loss: 1.0776 - val_accuracy: 0.4375\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 1.0511 - accuracy: 0.4175 - val_loss: 1.0259 - val_accuracy: 0.4125\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.8887 - accuracy: 0.5650 - val_loss: 0.7204 - val_accuracy: 0.7250\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.8539 - accuracy: 0.6025 - val_loss: 0.9149 - val_accuracy: 0.5000\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.8026 - accuracy: 0.6425 - val_loss: 0.6773 - val_accuracy: 0.7875\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7705 - accuracy: 0.6875 - val_loss: 0.8200 - val_accuracy: 0.6625\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7587 - accuracy: 0.6925 - val_loss: 0.8116 - val_accuracy: 0.6250\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7375 - accuracy: 0.6575 - val_loss: 0.7555 - val_accuracy: 0.6500\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7882 - accuracy: 0.6475 - val_loss: 0.7077 - val_accuracy: 0.7125\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7927 - accuracy: 0.6650 - val_loss: 0.6092 - val_accuracy: 0.7625\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7213 - accuracy: 0.6700 - val_loss: 0.7043 - val_accuracy: 0.6125\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7320 - accuracy: 0.6825 - val_loss: 0.8485 - val_accuracy: 0.6875\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7486 - accuracy: 0.6425 - val_loss: 0.7232 - val_accuracy: 0.6500\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7720 - accuracy: 0.6600 - val_loss: 0.7488 - val_accuracy: 0.6625\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6744 - accuracy: 0.6950 - val_loss: 0.7853 - val_accuracy: 0.7125\n",
      "INFO:tensorflow:Assets written to: model-9\\assets\n",
      "-- Evaluate --\n",
      "accuracy: 72.00%\n",
      "-- Predict --\n",
      "{'0_food': 0, '1_interior': 1, '2_exterior': 2}\n",
      "[[0.317 0.428 0.255]\n",
      " [0.068 0.639 0.293]\n",
      " [0.620 0.183 0.197]\n",
      " [0.853 0.133 0.014]\n",
      " [0.885 0.090 0.025]\n",
      " [0.608 0.304 0.087]\n",
      " [0.417 0.544 0.039]\n",
      " [0.778 0.067 0.155]\n",
      " [0.919 0.074 0.008]\n",
      " [0.097 0.331 0.572]\n",
      " [0.680 0.178 0.142]\n",
      " [0.745 0.233 0.022]\n",
      " [0.959 0.041 0.000]\n",
      " [0.219 0.618 0.163]\n",
      " [0.534 0.452 0.014]\n",
      " [0.035 0.378 0.586]\n",
      " [0.174 0.537 0.290]\n",
      " [0.200 0.321 0.480]\n",
      " [0.833 0.136 0.031]\n",
      " [0.231 0.309 0.460]\n",
      " [0.744 0.208 0.047]\n",
      " [0.912 0.074 0.014]\n",
      " [0.427 0.257 0.316]\n",
      " [0.129 0.117 0.754]\n",
      " [0.063 0.456 0.481]\n",
      " [0.550 0.395 0.055]\n",
      " [0.677 0.245 0.078]\n",
      " [0.361 0.340 0.299]\n",
      " [0.017 0.331 0.652]\n",
      " [0.346 0.554 0.100]\n",
      " [0.009 0.229 0.762]\n",
      " [0.335 0.616 0.049]\n",
      " [0.489 0.488 0.023]\n",
      " [0.734 0.213 0.053]\n",
      " [0.527 0.467 0.006]\n",
      " [0.128 0.739 0.133]\n",
      " [0.847 0.143 0.009]\n",
      " [0.588 0.229 0.183]\n",
      " [0.866 0.123 0.011]\n",
      " [0.250 0.336 0.414]\n",
      " [0.960 0.014 0.026]\n",
      " [0.039 0.889 0.072]\n",
      " [0.058 0.589 0.353]\n",
      " [0.251 0.648 0.101]\n",
      " [0.918 0.081 0.001]\n",
      " [0.203 0.644 0.153]\n",
      " [0.124 0.652 0.223]\n",
      " [0.066 0.434 0.500]\n",
      " [0.382 0.541 0.076]\n",
      " [0.995 0.005 0.000]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(300,300,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(16, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(32, activation='selu'))\n",
    "# model.add(Dense(2, activation='selu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정 및 요약\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=8,\n",
    "        epochs=15,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=8)\n",
    "\n",
    "model.save('model-9')\n",
    "\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}