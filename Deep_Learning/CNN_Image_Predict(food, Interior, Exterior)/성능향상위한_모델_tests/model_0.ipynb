{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 불러와서 numpy로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras로 이미지 불러오기 \n",
    "from keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "\n",
    "\n",
    "#음식 데이터 to numpy  , Label = 0\n",
    "data_fd = []\n",
    "data_fd_label = []\n",
    "for num in range(1,501):\n",
    "    #classes = ['exterior', 'interior','food']\n",
    "    image_file = './images/{}{}.jpg'.format('food', num)\n",
    "    image_array = img_to_array(load_img(image_file))\n",
    "    #print(image_array)\n",
    "    \n",
    "    data_fd.append(image_array)\n",
    "    data_fd_label.append(0)\n",
    "\n",
    "data_fd = np.array(data_fd)\n",
    "data_fd_label = np.array(data_fd_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#실내 데이터 to numpy  , Label = 1\n",
    "\n",
    "data_in = []\n",
    "data_in_label = []\n",
    "for num in range(1,501):\n",
    "    #classes = ['exterior', 'interior','food']\n",
    "    image_file = './images/{}{}.jpg'.format('interior', num)\n",
    "    image_array = img_to_array(load_img(image_file))\n",
    "    #print(image_array)\n",
    "    \n",
    "    data_in.append(image_array)\n",
    "    data_in_label.append(1)\n",
    "\n",
    "data_in = np.array(data_in)\n",
    "data_in_label = np.array(data_in_label)\n",
    "print(len(data_in))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(data_in_label).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [4, 5], 234, 23]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [[[1,2], [4,5]], [234,23]]\n",
    "answer = sum(my_list, [])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실외 데이터 to numpy  , Label = 2\n",
    "data_ex= []\n",
    "data_ex_label= []\n",
    "for num in range(1,2):\n",
    "    #classes = ['exterior', 'interior','food']\n",
    "    image_file = './images/{}{}.jpg'.format('exterior', num)\n",
    "    image_array = img_to_array(load_img(image_file))\n",
    "    #print(image_array)\n",
    "    data_ex.append(image_array)\n",
    "    \n",
    "    data_ex_label.append(2)\n",
    "    \n",
    "data_ex = np.array(data_ex)\n",
    "data_ex_label = np.array(data_ex_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 비율은 0.85 : 0.15 로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1275, 300, 300, 3)\n",
      "(225, 300, 300, 3)\n",
      "(1275,)\n",
      "(225,)\n",
      "[[[[184. 146. 109.]\n",
      "   [185. 147. 110.]\n",
      "   [185. 147. 110.]\n",
      "   ...\n",
      "   [ 73.  83.  75.]\n",
      "   [ 71.  80.  75.]\n",
      "   [ 72.  81.  76.]]\n",
      "\n",
      "  [[174. 137.  95.]\n",
      "   [175. 138.  96.]\n",
      "   [177. 140.  98.]\n",
      "   ...\n",
      "   [ 74.  85.  77.]\n",
      "   [ 67.  78.  72.]\n",
      "   [ 66.  75.  70.]]\n",
      "\n",
      "  [[158. 121.  77.]\n",
      "   [159. 122.  78.]\n",
      "   [160. 123.  78.]\n",
      "   ...\n",
      "   [ 64.  81.  71.]\n",
      "   [ 60.  76.  66.]\n",
      "   [ 64.  75.  67.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 10.   6.   3.]\n",
      "   [ 14.   9.   6.]\n",
      "   [ 16.   3.   0.]\n",
      "   ...\n",
      "   [184. 178. 166.]\n",
      "   [176. 172. 161.]\n",
      "   [173. 169. 158.]]\n",
      "\n",
      "  [[ 11.   9.  10.]\n",
      "   [ 14.   9.   6.]\n",
      "   [ 23.  10.   2.]\n",
      "   ...\n",
      "   [179. 175. 163.]\n",
      "   [178. 174. 163.]\n",
      "   [175. 173. 161.]]\n",
      "\n",
      "  [[ 23.  23.  25.]\n",
      "   [ 16.  10.  10.]\n",
      "   [ 24.  11.   3.]\n",
      "   ...\n",
      "   [179. 175. 163.]\n",
      "   [179. 177. 165.]\n",
      "   [179. 176. 167.]]]\n",
      "\n",
      "\n",
      " [[[ 29.  19.   7.]\n",
      "   [ 30.  20.   8.]\n",
      "   [ 28.  18.   6.]\n",
      "   ...\n",
      "   [126. 114. 102.]\n",
      "   [125. 113. 101.]\n",
      "   [128. 116. 104.]]\n",
      "\n",
      "  [[ 29.  19.   7.]\n",
      "   [ 31.  21.   9.]\n",
      "   [ 30.  20.   8.]\n",
      "   ...\n",
      "   [127. 115. 103.]\n",
      "   [124. 112. 100.]\n",
      "   [119. 107.  95.]]\n",
      "\n",
      "  [[ 30.  20.  10.]\n",
      "   [ 32.  22.  12.]\n",
      "   [ 31.  21.  11.]\n",
      "   ...\n",
      "   [124. 112. 100.]\n",
      "   [119. 107.  95.]\n",
      "   [119. 107.  95.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[163. 157. 183.]\n",
      "   [190. 185. 208.]\n",
      "   [212. 207. 227.]\n",
      "   ...\n",
      "   [180. 185. 179.]\n",
      "   [173. 178. 172.]\n",
      "   [176. 181. 175.]]\n",
      "\n",
      "  [[200. 191. 218.]\n",
      "   [191. 183. 207.]\n",
      "   [190. 185. 207.]\n",
      "   ...\n",
      "   [178. 183. 177.]\n",
      "   [172. 177. 171.]\n",
      "   [172. 177. 171.]]\n",
      "\n",
      "  [[194. 184. 209.]\n",
      "   [185. 177. 201.]\n",
      "   [179. 174. 196.]\n",
      "   ...\n",
      "   [173. 178. 172.]\n",
      "   [170. 175. 169.]\n",
      "   [167. 172. 166.]]]\n",
      "\n",
      "\n",
      " [[[206. 196. 207.]\n",
      "   [206. 196. 207.]\n",
      "   [207. 197. 208.]\n",
      "   ...\n",
      "   [ 87.  85.  99.]\n",
      "   [ 92.  90. 104.]\n",
      "   [ 95.  93. 107.]]\n",
      "\n",
      "  [[202. 192. 203.]\n",
      "   [202. 192. 203.]\n",
      "   [202. 192. 203.]\n",
      "   ...\n",
      "   [ 85.  83.  97.]\n",
      "   [ 90.  88. 102.]\n",
      "   [ 93.  91. 105.]]\n",
      "\n",
      "  [[202. 192. 203.]\n",
      "   [201. 191. 202.]\n",
      "   [201. 191. 202.]\n",
      "   ...\n",
      "   [ 86.  84.  98.]\n",
      "   [ 89.  87. 101.]\n",
      "   [ 93.  91. 105.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[129. 118. 126.]\n",
      "   [122. 111. 119.]\n",
      "   [120. 107. 114.]\n",
      "   ...\n",
      "   [138.  80.  30.]\n",
      "   [134.  74.  24.]\n",
      "   [128.  66.  17.]]\n",
      "\n",
      "  [[114. 103. 111.]\n",
      "   [107.  96. 104.]\n",
      "   [107.  94. 101.]\n",
      "   ...\n",
      "   [132.  74.  24.]\n",
      "   [131.  71.  21.]\n",
      "   [129.  67.  18.]]\n",
      "\n",
      "  [[ 61.  50.  58.]\n",
      "   [ 58.  47.  55.]\n",
      "   [ 65.  52.  59.]\n",
      "   ...\n",
      "   [125.  67.  17.]\n",
      "   [128.  68.  18.]\n",
      "   [130.  68.  19.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   ...\n",
      "   [241. 238. 249.]\n",
      "   [ 72.  66.  78.]\n",
      "   [119. 113. 127.]]\n",
      "\n",
      "  [[254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   ...\n",
      "   [218. 214. 228.]\n",
      "   [166. 159. 175.]\n",
      "   [196. 189. 207.]]\n",
      "\n",
      "  [[254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   [254. 254. 254.]\n",
      "   ...\n",
      "   [254. 250. 255.]\n",
      "   [197. 193. 208.]\n",
      "   [ 37.  29.  50.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 35.  36.  22.]\n",
      "   [ 35.  36.  22.]\n",
      "   [ 42.  43.  29.]\n",
      "   ...\n",
      "   [ 60.  74.  25.]\n",
      "   [ 59.  73.  24.]\n",
      "   [ 57.  70.  26.]]\n",
      "\n",
      "  [[ 36.  37.  21.]\n",
      "   [ 35.  36.  20.]\n",
      "   [ 41.  42.  26.]\n",
      "   ...\n",
      "   [ 91. 105.  56.]\n",
      "   [ 64.  78.  29.]\n",
      "   [ 46.  59.  13.]]\n",
      "\n",
      "  [[ 34.  35.  19.]\n",
      "   [ 42.  43.  27.]\n",
      "   [ 46.  47.  31.]\n",
      "   ...\n",
      "   [ 73.  85.  45.]\n",
      "   [ 61.  73.  33.]\n",
      "   [ 34.  44.   9.]]]\n",
      "\n",
      "\n",
      " [[[120.  97.  91.]\n",
      "   [120.  97.  91.]\n",
      "   [119.  96.  90.]\n",
      "   ...\n",
      "   [197. 189. 186.]\n",
      "   [184. 176. 173.]\n",
      "   [179. 171. 168.]]\n",
      "\n",
      "  [[120.  97.  91.]\n",
      "   [120.  97.  91.]\n",
      "   [121.  98.  92.]\n",
      "   ...\n",
      "   [195. 187. 184.]\n",
      "   [182. 174. 171.]\n",
      "   [175. 167. 164.]]\n",
      "\n",
      "  [[117.  94.  88.]\n",
      "   [118.  95.  89.]\n",
      "   [120.  97.  91.]\n",
      "   ...\n",
      "   [195. 187. 184.]\n",
      "   [181. 173. 170.]\n",
      "   [173. 165. 162.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[159. 166. 158.]\n",
      "   [158. 165. 157.]\n",
      "   [157. 164. 156.]\n",
      "   ...\n",
      "   [239. 233. 221.]\n",
      "   [239. 233. 221.]\n",
      "   [239. 233. 221.]]\n",
      "\n",
      "  [[155. 162. 154.]\n",
      "   [154. 161. 153.]\n",
      "   [153. 160. 152.]\n",
      "   ...\n",
      "   [239. 233. 221.]\n",
      "   [239. 233. 221.]\n",
      "   [239. 233. 221.]]\n",
      "\n",
      "  [[151. 158. 150.]\n",
      "   [151. 158. 150.]\n",
      "   [150. 157. 149.]\n",
      "   ...\n",
      "   [239. 233. 221.]\n",
      "   [239. 233. 221.]\n",
      "   [239. 233. 221.]]]\n",
      "\n",
      "\n",
      " [[[154. 153. 151.]\n",
      "   [166. 165. 163.]\n",
      "   [140. 139. 137.]\n",
      "   ...\n",
      "   [228. 217. 211.]\n",
      "   [234. 223. 217.]\n",
      "   [233. 222. 216.]]\n",
      "\n",
      "  [[199. 198. 196.]\n",
      "   [221. 220. 218.]\n",
      "   [174. 173. 169.]\n",
      "   ...\n",
      "   [222. 211. 205.]\n",
      "   [216. 205. 199.]\n",
      "   [216. 207. 200.]]\n",
      "\n",
      "  [[205. 204. 200.]\n",
      "   [216. 212. 209.]\n",
      "   [176. 172. 169.]\n",
      "   ...\n",
      "   [177. 168. 161.]\n",
      "   [179. 170. 163.]\n",
      "   [191. 182. 175.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[140. 122.  98.]\n",
      "   [130. 112.  88.]\n",
      "   [138. 120.  96.]\n",
      "   ...\n",
      "   [198. 197. 192.]\n",
      "   [208. 207. 202.]\n",
      "   [205. 204. 199.]]\n",
      "\n",
      "  [[134. 116.  92.]\n",
      "   [131. 113.  89.]\n",
      "   [140. 124.  99.]\n",
      "   ...\n",
      "   [204. 203. 198.]\n",
      "   [213. 212. 207.]\n",
      "   [207. 206. 201.]]\n",
      "\n",
      "  [[129. 113.  88.]\n",
      "   [131. 115.  90.]\n",
      "   [142. 126. 100.]\n",
      "   ...\n",
      "   [209. 208. 203.]\n",
      "   [217. 216. 211.]\n",
      "   [208. 207. 203.]]]]\n"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.85\n",
    "\n",
    "train_data_fd = int(len(data_fd)*train_test_split)\n",
    "train_data_in = int(len(data_in)*train_test_split)\n",
    "train_data_ex = int(len(data_ex)*train_test_split)\n",
    "#print(train_data_fd,train_data_in,train_data_ex)\n",
    "\n",
    "\n",
    "\n",
    "#print(len(data_fd[:train_data_fd]))\n",
    "\n",
    "\n",
    "#  X_train , X_test 만들기 \n",
    "X_train_data_set = np.concatenate((data_fd[:train_data_fd], data_in[:train_data_in], data_ex[:train_data_ex]), axis= 0)\n",
    "print(X_train_data_set.shape)\n",
    "X_test_data_set =np.concatenate((data_fd[train_data_fd: ], data_in[train_data_in:], data_ex[train_data_ex:]))\n",
    "print(X_test_data_set.shape)\n",
    "\n",
    "y_train_data_set = np.concatenate((data_fd_label[:train_data_fd], data_in_label[:train_data_in], data_ex_label[:train_data_ex]))\n",
    "y_test_data_set =np.concatenate((data_fd_label[train_data_fd: ], data_in_label[train_data_in:], data_ex_label[train_data_ex:]))\n",
    "print(y_train_data_set.shape)\n",
    "print(y_test_data_set.shape)\n",
    "\n",
    "print(X_train_data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train_0, y_train_0 = shuffle(X_train_data_set, y_train_data_set, random_state=42)\n",
    "X_test_0, y_test_0= shuffle(X_test_data_set, y_test_data_set, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(history):\n",
    "    plt.figure(figsize = (5,3))\n",
    "    \n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    \n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['train','test'], loc = 'upper right')\n",
    "    plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 515. MiB for an array with shape (500, 300, 300, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-245-f22e67e4b865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_test_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0mimage_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-245-f22e67e4b865>\u001b[0m in \u001b[0;36mimage_load_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdata_fd_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mdata_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mdata_fd_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fd_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 515. MiB for an array with shape (500, 300, 300, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "def image_load_data():\n",
    "    #음식 데이터 to numpy  , Label = 0\n",
    "    data_fd = []\n",
    "    data_fd_label = []\n",
    "    for num in range(1,501):\n",
    "        #classes = ['exterior', 'interior','food']\n",
    "        image_file = './images/{}{}.jpg'.format('food', num)\n",
    "        image_array = img_to_array(load_img(image_file))\n",
    "        #print(image_array)\n",
    "\n",
    "        data_fd.append(image_array)\n",
    "        data_fd_label.append(0)\n",
    "\n",
    "    data_fd = np.array(data_fd)\n",
    "    data_fd_label = np.array(data_fd_label)\n",
    "\n",
    "    #실내 데이터 to numpy  , Label = 1\n",
    "\n",
    "    data_in = []\n",
    "    data_in_label = []\n",
    "    for num in range(1,501):\n",
    "        #classes = ['exterior', 'interior','food']\n",
    "        image_file = './images/{}{}.jpg'.format('interior', num)\n",
    "        image_array = img_to_array(load_img(image_file))\n",
    "        #print(image_array)\n",
    "\n",
    "        data_in.append(image_array)\n",
    "        data_in_label.append(1)\n",
    "\n",
    "    data_in = np.array(data_in)\n",
    "    data_in_label = np.array(data_in_label)\n",
    "    print(len(data_in))\n",
    "\n",
    "\n",
    "    #실외 데이터 to numpy  , Label = 2\n",
    "    data_ex= []\n",
    "    data_ex_label= []\n",
    "    for num in range(1,2):\n",
    "        #classes = ['exterior', 'interior','food']\n",
    "        image_file = './images/{}{}.jpg'.format('exterior', num)\n",
    "        image_array = img_to_array(load_img(image_file))\n",
    "        #print(image_array)\n",
    "        data_ex.append(image_array)\n",
    "\n",
    "        data_ex_label.append(2)\n",
    "\n",
    "    data_ex = np.array(data_ex)\n",
    "    data_ex_label = np.array(data_ex_label)\n",
    "\n",
    "    train_test_split = 0.85\n",
    "\n",
    "    train_data_fd = int(len(data_fd)*train_test_split)\n",
    "    train_data_in = int(len(data_in)*train_test_split)\n",
    "    train_data_ex = int(len(data_ex)*train_test_split)\n",
    "    #print(train_data_fd,train_data_in,train_data_ex)\n",
    "\n",
    "\n",
    "\n",
    "    #print(len(data_fd[:train_data_fd]))\n",
    "\n",
    "\n",
    "    #  X_train , X_test 만들기 \n",
    "    X_train_data_set = np.concatenate((data_fd[:train_data_fd], data_in[:train_data_in], data_ex[:train_data_ex]))\n",
    "    print(X_train_data_set.shape)\n",
    "    X_test_data_set =np.concatenate((data_fd[train_data_fd: ], data_in[train_data_in:], data_ex[train_data_ex:]))\n",
    "    print(X_test_data_set.shape)\n",
    "\n",
    "    y_train_data_set = np.concatenate((data_fd_label[:train_data_fd], data_in_label[:train_data_in], data_ex_label[:train_data_ex]))\n",
    "    y_test_data_set =np.concatenate((data_fd_label[train_data_fd: ], data_in_label[train_data_in:], data_ex_label[train_data_ex:]))\n",
    "    print(y_train_data_set.shape)\n",
    "    print(y_test_data_set.shape)\n",
    "\n",
    "    print(X_train_data_set)\n",
    "\n",
    "\n",
    "    from sklearn.utils import shuffle\n",
    "    X_train_0, y_train_0 = shuffle(X_train_data_set, y_train_data_set, random_state=42)\n",
    "    X_test_0, y_test_0= shuffle(X_test_data_set, y_test_data_set, random_state=42)\n",
    "\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    return (X_train_0, y_train_0) ,( X_test_0, y_test_0)\n",
    "\n",
    "image_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 298, 298, 4)       112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 149, 149, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 147, 147, 8)       296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 73, 73, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 42632)             0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 3)                 127899    \n",
      "=================================================================\n",
      "Total params: 128,307\n",
      "Trainable params: 128,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[15,298,298,4] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node sequential_7/conv_layer1/Relu (defined at <ipython-input-202-6e80fcfe988d>:36) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_10851]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-6290e24697ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mtrain_mnist_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-202-6e80fcfe988d>\u001b[0m in \u001b[0;36mtrain_mnist_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mplot_loss_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[15,298,298,4] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node sequential_7/conv_layer1/Relu (defined at <ipython-input-202-6e80fcfe988d>:36) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_10851]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "def train_image_model():\n",
    "    #(X_train, y_train) = X_train, y_train\n",
    "    #(X_test, y_test) = X_test, y_test\n",
    "    X_train = X_train_0.reshape(len(X_train_data_set),300,300,3) \n",
    "    X_test = X_test_0.reshape(len(X_test_data_set),300,300,3)\n",
    "    y_train = to_categorical(y_train_0)\n",
    "    y_test = to_categorical(y_test_0)\n",
    "    \n",
    "    #print(y_train[0])\n",
    "    \n",
    "    \n",
    "    model = Sequential([\n",
    "                #고정\n",
    "                Input(shape=(300,300,3), name='input_layer'),\n",
    "                \n",
    "                # n_filters * (filter_size + 1) = 32*(9+1) = 320\n",
    "                Conv2D(32, kernel_size=3, activation='relu', name='conv_layer1'),\n",
    "                \n",
    "                \n",
    "                #Dropout(0.5)\n",
    "                MaxPooling2D(pool_size=2),\n",
    "                Conv2D(8, kernel_size=3, activation='relu', name='conv_layer2'),\n",
    "                MaxPooling2D(pool_size=2),\n",
    "                Flatten(),\n",
    "                #Dense(20, activation='softmax', name='output_layer')\n",
    "        \n",
    "        \n",
    "                #고정\n",
    "                Dense(3, activation='softmax', name='output_layer')\n",
    "            ])\n",
    "\n",
    "    model.summary()    \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=15, epochs=3)\n",
    "    plot_loss_curve(history.history)\n",
    "    print(history.history)\n",
    "    print(\"train loss=\", history.history['loss'][-1])\n",
    "    print(\"validation loss=\", history.history['val_loss'][-1])    \n",
    "    \n",
    "    model.save('model-201814132')\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    train_mnist_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_image_model():\n",
    "    (X_train, y_train), (X_test, y_test) = ************데이터 어떻게 불러올거야? \n",
    "    #X_train = X_train.reshape(60000,28,28,3) \n",
    "    #X_test = X_test.reshape(10000,28,28,3)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "#     print(y_train[1563])\n",
    "    \n",
    "    \n",
    "    #옵티마이저, loss , 변경해보기\n",
    "    model.compile(optimizer= 'adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    history = model.fit(X_train,y_train, validation_data=(X_test, y_test), batch_size=20, epochs = 3)\n",
    "    \n",
    "    plot_loss_curve(history.history)\n",
    "    print(history.history)\n",
    "    print('train loss =', history.history['loss'][-1])\n",
    "    print('validation loss =', history.history['val_loss'][-1])\n",
    "\n",
    "    model.save('model-201814132')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "test_id = -1\n",
    "if test_id <0 :\n",
    "    from random import randrange\n",
    "    test_sample_id = randrange(30)\n",
    "else:\n",
    "    test_sample_id = test_id\n",
    "\n",
    "test_image =X_test[test_sample_id]\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 784 into shape (1,8,49,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-228-96ed4024e882>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_actual\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_pred_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mpredict_image_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-228-96ed4024e882>\u001b[0m in \u001b[0;36mpredict_image_sample\u001b[1;34m(model, X_test, y_test, test_id)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     plt.imshow(test_image, cmap = 'gray')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0my_actual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_sample_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (1,8,49,3)"
     ]
    }
   ],
   "source": [
    "def predict_image_sample(model,X_test, y_test, test_id= -1 ):\n",
    "    if test_id <0 :\n",
    "        from random import randrange\n",
    "        test_sample_id = randrange(30)\n",
    "    else:\n",
    "        test_sample_id = test_id\n",
    "    \n",
    "    test_image =X_test[test_sample_id]\n",
    "    print(X_test)\n",
    "#     plt.imshow(test_image, cmap = 'gray')\n",
    "    \n",
    "    test_image = test_image.reshape(1,8,49,3)\n",
    "    \n",
    "    y_actual = y_test[test_sample_id]\n",
    "    #print('y_actual number = ', y_actual)\n",
    "    \n",
    "    y_pred = model.predict(test_image)\n",
    "    #print(\"y_pred = \", y_pred)\n",
    "    y_pred_num = np.argmax(y_pred, axis = 1)[0]\n",
    "    #print('y_pred number = ', y_pred)\n",
    "    \n",
    "    return y_actual , y_pred_num\n",
    "    \n",
    "predict_image_sample(model,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "(850, 300, 300, 3)\n",
      "(151, 300, 300, 3)\n",
      "(850,)\n",
      "(151,)\n",
      "[[[[184. 146. 109.]\n",
      "   [185. 147. 110.]\n",
      "   [185. 147. 110.]\n",
      "   ...\n",
      "   [ 73.  83.  75.]\n",
      "   [ 71.  80.  75.]\n",
      "   [ 72.  81.  76.]]\n",
      "\n",
      "  [[174. 137.  95.]\n",
      "   [175. 138.  96.]\n",
      "   [177. 140.  98.]\n",
      "   ...\n",
      "   [ 74.  85.  77.]\n",
      "   [ 67.  78.  72.]\n",
      "   [ 66.  75.  70.]]\n",
      "\n",
      "  [[158. 121.  77.]\n",
      "   [159. 122.  78.]\n",
      "   [160. 123.  78.]\n",
      "   ...\n",
      "   [ 64.  81.  71.]\n",
      "   [ 60.  76.  66.]\n",
      "   [ 64.  75.  67.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 10.   6.   3.]\n",
      "   [ 14.   9.   6.]\n",
      "   [ 16.   3.   0.]\n",
      "   ...\n",
      "   [184. 178. 166.]\n",
      "   [176. 172. 161.]\n",
      "   [173. 169. 158.]]\n",
      "\n",
      "  [[ 11.   9.  10.]\n",
      "   [ 14.   9.   6.]\n",
      "   [ 23.  10.   2.]\n",
      "   ...\n",
      "   [179. 175. 163.]\n",
      "   [178. 174. 163.]\n",
      "   [175. 173. 161.]]\n",
      "\n",
      "  [[ 23.  23.  25.]\n",
      "   [ 16.  10.  10.]\n",
      "   [ 24.  11.   3.]\n",
      "   ...\n",
      "   [179. 175. 163.]\n",
      "   [179. 177. 165.]\n",
      "   [179. 176. 167.]]]\n",
      "\n",
      "\n",
      " [[[ 29.  19.   7.]\n",
      "   [ 30.  20.   8.]\n",
      "   [ 28.  18.   6.]\n",
      "   ...\n",
      "   [126. 114. 102.]\n",
      "   [125. 113. 101.]\n",
      "   [128. 116. 104.]]\n",
      "\n",
      "  [[ 29.  19.   7.]\n",
      "   [ 31.  21.   9.]\n",
      "   [ 30.  20.   8.]\n",
      "   ...\n",
      "   [127. 115. 103.]\n",
      "   [124. 112. 100.]\n",
      "   [119. 107.  95.]]\n",
      "\n",
      "  [[ 30.  20.  10.]\n",
      "   [ 32.  22.  12.]\n",
      "   [ 31.  21.  11.]\n",
      "   ...\n",
      "   [124. 112. 100.]\n",
      "   [119. 107.  95.]\n",
      "   [119. 107.  95.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[163. 157. 183.]\n",
      "   [190. 185. 208.]\n",
      "   [212. 207. 227.]\n",
      "   ...\n",
      "   [180. 185. 179.]\n",
      "   [173. 178. 172.]\n",
      "   [176. 181. 175.]]\n",
      "\n",
      "  [[200. 191. 218.]\n",
      "   [191. 183. 207.]\n",
      "   [190. 185. 207.]\n",
      "   ...\n",
      "   [178. 183. 177.]\n",
      "   [172. 177. 171.]\n",
      "   [172. 177. 171.]]\n",
      "\n",
      "  [[194. 184. 209.]\n",
      "   [185. 177. 201.]\n",
      "   [179. 174. 196.]\n",
      "   ...\n",
      "   [173. 178. 172.]\n",
      "   [170. 175. 169.]\n",
      "   [167. 172. 166.]]]\n",
      "\n",
      "\n",
      " [[[206. 196. 207.]\n",
      "   [206. 196. 207.]\n",
      "   [207. 197. 208.]\n",
      "   ...\n",
      "   [ 87.  85.  99.]\n",
      "   [ 92.  90. 104.]\n",
      "   [ 95.  93. 107.]]\n",
      "\n",
      "  [[202. 192. 203.]\n",
      "   [202. 192. 203.]\n",
      "   [202. 192. 203.]\n",
      "   ...\n",
      "   [ 85.  83.  97.]\n",
      "   [ 90.  88. 102.]\n",
      "   [ 93.  91. 105.]]\n",
      "\n",
      "  [[202. 192. 203.]\n",
      "   [201. 191. 202.]\n",
      "   [201. 191. 202.]\n",
      "   ...\n",
      "   [ 86.  84.  98.]\n",
      "   [ 89.  87. 101.]\n",
      "   [ 93.  91. 105.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[129. 118. 126.]\n",
      "   [122. 111. 119.]\n",
      "   [120. 107. 114.]\n",
      "   ...\n",
      "   [138.  80.  30.]\n",
      "   [134.  74.  24.]\n",
      "   [128.  66.  17.]]\n",
      "\n",
      "  [[114. 103. 111.]\n",
      "   [107.  96. 104.]\n",
      "   [107.  94. 101.]\n",
      "   ...\n",
      "   [132.  74.  24.]\n",
      "   [131.  71.  21.]\n",
      "   [129.  67.  18.]]\n",
      "\n",
      "  [[ 61.  50.  58.]\n",
      "   [ 58.  47.  55.]\n",
      "   [ 65.  52.  59.]\n",
      "   ...\n",
      "   [125.  67.  17.]\n",
      "   [128.  68.  18.]\n",
      "   [130.  68.  19.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[155. 156. 151.]\n",
      "   [156. 157. 152.]\n",
      "   [156. 157. 152.]\n",
      "   ...\n",
      "   [149. 155. 167.]\n",
      "   [151. 155. 167.]\n",
      "   [149. 151. 163.]]\n",
      "\n",
      "  [[155. 156. 151.]\n",
      "   [155. 156. 151.]\n",
      "   [156. 157. 152.]\n",
      "   ...\n",
      "   [143. 150. 160.]\n",
      "   [144. 151. 161.]\n",
      "   [148. 152. 163.]]\n",
      "\n",
      "  [[155. 156. 151.]\n",
      "   [155. 156. 151.]\n",
      "   [155. 156. 151.]\n",
      "   ...\n",
      "   [145. 154. 163.]\n",
      "   [146. 155. 164.]\n",
      "   [147. 156. 165.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 62.  60.  47.]\n",
      "   [ 63.  61.  48.]\n",
      "   [ 65.  63.  50.]\n",
      "   ...\n",
      "   [110.  97.  78.]\n",
      "   [106.  93.  74.]\n",
      "   [101.  88.  71.]]\n",
      "\n",
      "  [[ 63.  61.  48.]\n",
      "   [ 64.  62.  49.]\n",
      "   [ 66.  64.  51.]\n",
      "   ...\n",
      "   [115. 102.  83.]\n",
      "   [114. 101.  82.]\n",
      "   [105.  92.  75.]]\n",
      "\n",
      "  [[ 64.  62.  49.]\n",
      "   [ 64.  62.  49.]\n",
      "   [ 64.  62.  49.]\n",
      "   ...\n",
      "   [120. 107.  88.]\n",
      "   [121. 108.  89.]\n",
      "   [110.  97.  80.]]]\n",
      "\n",
      "\n",
      " [[[209. 209. 219.]\n",
      "   [206. 206. 216.]\n",
      "   [213. 213. 223.]\n",
      "   ...\n",
      "   [191. 184. 178.]\n",
      "   [196. 187. 182.]\n",
      "   [197. 188. 183.]]\n",
      "\n",
      "  [[204. 204. 214.]\n",
      "   [213. 213. 223.]\n",
      "   [211. 211. 221.]\n",
      "   ...\n",
      "   [198. 191. 185.]\n",
      "   [200. 193. 187.]\n",
      "   [201. 192. 187.]]\n",
      "\n",
      "  [[213. 213. 223.]\n",
      "   [207. 207. 217.]\n",
      "   [204. 204. 214.]\n",
      "   ...\n",
      "   [202. 195. 189.]\n",
      "   [204. 196. 193.]\n",
      "   [204. 196. 193.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[131. 115. 100.]\n",
      "   [129. 113.  98.]\n",
      "   [129. 113.  98.]\n",
      "   ...\n",
      "   [107.  97.  87.]\n",
      "   [106.  96.  86.]\n",
      "   [106.  96.  86.]]\n",
      "\n",
      "  [[132. 116. 101.]\n",
      "   [130. 114.  99.]\n",
      "   [132. 116. 101.]\n",
      "   ...\n",
      "   [116. 106.  96.]\n",
      "   [116. 106.  96.]\n",
      "   [116. 106.  96.]]\n",
      "\n",
      "  [[127. 111.  95.]\n",
      "   [126. 110.  94.]\n",
      "   [129. 113.  97.]\n",
      "   ...\n",
      "   [118. 106.  94.]\n",
      "   [119. 106.  97.]\n",
      "   [120. 107.  98.]]]\n",
      "\n",
      "\n",
      " [[[149. 104.  71.]\n",
      "   [149. 104.  71.]\n",
      "   [148. 103.  70.]\n",
      "   ...\n",
      "   [173. 164. 157.]\n",
      "   [184. 175. 168.]\n",
      "   [193. 184. 177.]]\n",
      "\n",
      "  [[149. 104.  71.]\n",
      "   [149. 104.  71.]\n",
      "   [148. 103.  70.]\n",
      "   ...\n",
      "   [243. 239. 236.]\n",
      "   [241. 237. 234.]\n",
      "   [238. 234. 231.]]\n",
      "\n",
      "  [[149. 104.  71.]\n",
      "   [149. 104.  71.]\n",
      "   [148. 103.  70.]\n",
      "   ...\n",
      "   [133. 138. 142.]\n",
      "   [123. 128. 132.]\n",
      "   [114. 119. 123.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[227. 185. 137.]\n",
      "   [227. 185. 137.]\n",
      "   [227. 185. 137.]\n",
      "   ...\n",
      "   [ 76.  55.  52.]\n",
      "   [ 85.  61.  59.]\n",
      "   [ 92.  66.  65.]]\n",
      "\n",
      "  [[227. 185. 137.]\n",
      "   [227. 185. 137.]\n",
      "   [227. 185. 137.]\n",
      "   ...\n",
      "   [ 80.  56.  52.]\n",
      "   [ 88.  60.  57.]\n",
      "   [ 95.  65.  63.]]\n",
      "\n",
      "  [[227. 185. 137.]\n",
      "   [227. 185. 137.]\n",
      "   [227. 185. 137.]\n",
      "   ...\n",
      "   [ 84.  56.  52.]\n",
      "   [ 90.  61.  57.]\n",
      "   [ 99.  65.  63.]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-bf157df70ab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model-201814132'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     predict_image_sample(model,X_test, y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_image_sample(model,X_test, y_test, test_id= -1 ):\n",
    "    if test_id <0 :\n",
    "        from random import randrange\n",
    "        test_sample_id = randrange(10000)\n",
    "    else:\n",
    "        test_sample_id = test_id\n",
    "    \n",
    "    test_image =X_test[test_sample_id]\n",
    "#     plt.imshow(test_image, cmap = 'gray')\n",
    "    \n",
    "    test_image = test_image.reshape(1,300,300,3)\n",
    "    \n",
    "    y_actual = y_test[test_sample_id]\n",
    "    print('y_actual number = ', y_actual)\n",
    "    \n",
    "    y_pred = model.predict(test_image)\n",
    "    print(\"y_pred = \", y_pred)\n",
    "    y_pred_num = np.argmax(y_pred, axis = 1)[0]\n",
    "    print('y_pred number = ', y_pred)\n",
    "    return y_actual , y_pred_num\n",
    "'''    \n",
    "if __name__ == '__main__' :\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    model = load_model('mnist.model')\n",
    "    predict_image_sample(model,X_test, y_test)\n",
    "'''    \n",
    "    \n",
    "if __name__ == '__main__' :\n",
    "    n = 0\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    model = load_model('mnist.model')\n",
    "#     predict_image_sample(model,X_test, y_test)\n",
    "    \n",
    "    for i in range(700):\n",
    "        y_actual , y_pred_num = predict_image_sample(model,X_test, y_test,test_id = i)\n",
    "        if y_actual == y_pred_num:\n",
    "            n += 1 \n",
    "        else : pass\n",
    "print('전체 횟수 :', i,' '*10,'예측 성공 횟수',n,'\\n'*2 ,'정확도 = ', (n/i)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
